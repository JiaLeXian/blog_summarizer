{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dde751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e83b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-hjswwftf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-hjswwftf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/openai/whisper.git to commit 9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in /home/ec2-user/.local/lib/python3.9/site-packages (from whisper==1.0) (1.22.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from whisper==1.0) (1.12.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/.local/lib/python3.9/site-packages (from whisper==1.0) (4.62.3)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from whisper==1.0) (8.14.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from whisper==1.0) (4.23.0)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from whisper==1.0) (0.2.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/.local/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (3.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2021.11.10)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch->whisper==1.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 18:32:50.046536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 18:32:50.181435: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-03 18:32:50.217680: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-03 18:32:50.847866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2022-11-03 18:32:50.847974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2022-11-03 18:32:50.847982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model from: https://huggingface.co/facebook/bart-large-cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "/home/ec2-user/anaconda3/envs/deep-learning/lib/python3.9/site-packages/gradio/interface.py:328: UserWarning: Currently, only the 'default' theme is supported.\n",
      "  warnings.warn(\"Currently, only the 'default' theme is supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://62ce32cf78a3406a.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://62ce32cf78a3406a.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fdc8530e940>,\n",
       " 'http://127.0.0.1:7863/',\n",
       " 'https://62ce32cf78a3406a.gradio.app')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"pip install git+https://github.com/openai/whisper.git\")\n",
    "import gradio as gr\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "import gradio as gr\n",
    "from gradio.mix import Parallel, Series\n",
    "import nltk\n",
    " \n",
    "#from convert import main\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "  \n",
    " \n",
    "nltk.download('punkt')\n",
    "\n",
    "def extract_article_text(url):\n",
    "  USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
    "  config = Config()\n",
    "  config.browser_user_agent = USER_AGENT\n",
    "  config.request_timeout = 10\n",
    "\n",
    "  article = Article(url, config=config)\n",
    "  article.download()\n",
    "  article.parse()\n",
    "  text = article.text\n",
    "  return text\n",
    "\n",
    "extractor = gr.Interface(extract_article_text, 'text', 'text')\n",
    "summarizer = gr.Interface.load(\"huggingface/facebook/bart-large-cnn\")\n",
    "\n",
    "sample_url = [['https://www.cnbc.com/2022/11/02/fed-hikes-by-another-three-quarters-of-a-point-taking-rates-to-the-highest-level-since-january-2008.html'],\n",
    "               \n",
    "    ]\n",
    "           \n",
    "description =  '''\n",
    "        Note: A news article behind a paywall may produce an error.\n",
    "        '''\n",
    "  \n",
    "iface = Series(extractor, summarizer, \n",
    "  inputs = gr.inputs.Textbox(\n",
    "      lines = 2,\n",
    "      label = 'URL'\n",
    "  ),\n",
    "  outputs = 'text',\n",
    "  title = 'News Summarizer',\n",
    "  theme = 'peach',\n",
    "  description = description,\n",
    "  examples=sample_url)\n",
    "  \n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://www.vogue.com/article/latinx-beauty-brands\"\n",
    "#URL = \"https://hackernoon.com/will-the-game-stop-with-gamestop-or-is-this-just-the-beginning-2j1x32aa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e27f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83423a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "results = soup.find_all(['h1', 'p'])\n",
    "text = [result.text for result in results]\n",
    "ARTICLE = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chunk = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = ARTICLE.replace('.', '.<eos>')\n",
    "ARTICLE = ARTICLE.replace('?', '?<eos>')\n",
    "ARTICLE = ARTICLE.replace('!', '!<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ARTICLE.split('<eos>')\n",
    "current_chunk = 0 \n",
    "chunks = []\n",
    "for sentence in sentences:\n",
    "    if len(chunks) == current_chunk + 1: \n",
    "        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
    "            chunks[current_chunk].extend(sentence.split(' '))\n",
    "        else:\n",
    "            current_chunk += 1\n",
    "            chunks.append(sentence.split(' '))\n",
    "    else:\n",
    "        print(current_chunk)\n",
    "        chunks.append(sentence.split(' '))\n",
    "\n",
    "for chunk_id in range(len(chunks)):\n",
    "    chunks[chunk_id] = ' '.join(chunks[chunk_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f51856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = summarizer(chunks, max_length=200, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce112f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([summ['summary_text'] for summ in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42501ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([summ['summary_text'] for summ in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('blogsummary.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
